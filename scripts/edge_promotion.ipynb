{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from Swing.util.Evaluator import Evaluator\n",
    "from Swing.util.lag_identification import get_experiment_list, xcorr_experiments, calc_edge_lag\n",
    "from nxpd import draw\n",
    "from nxpd import nxpdParams\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from scipy.stats import fisher_exact, linregress, ttest_rel\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions!\n",
    "\n",
    "#### Note: Several of the functions do not pass variables correctly. Code will need to be cleaned if shared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def is_square(n):\n",
    "    \"\"\"\n",
    "    Determine if a number is a perfect square\n",
    "    :param n: int or float\n",
    "        The number to check\n",
    "    :return: Boolean\n",
    "        Return True if the number is a perfect square\n",
    "    \"\"\"\n",
    "    return np.sqrt(n).is_integer()\n",
    "\n",
    "\n",
    "def get_factors(n):\n",
    "    \"\"\"\n",
    "    Calculate the factors of a number\n",
    "    :param n: int\n",
    "        The number to be factored\n",
    "    :return: list\n",
    "        A sorted list of the unique factors from smallest to largest\n",
    "    \"\"\"\n",
    "    factor_list = np.array([[i, n // i] for i in range(1, int(n ** 0.5) + 1) if n % i == 0]).flatten().astype(int)\n",
    "    return sorted(factor_list.tolist())\n",
    "\n",
    "\n",
    "def calc_subplot_dimensions(x):\n",
    "    \"\"\"\n",
    "    Calculate the dimensions for a matplotlib subplot object.\n",
    "    :param x: int\n",
    "        Number of plots that need to be made\n",
    "    :return: rows, columns\n",
    "        The number of rows and columns that should be in the subplot\n",
    "    \"\"\"\n",
    "    if x <= 3:\n",
    "        rows = x\n",
    "        columns = 1\n",
    "    else:\n",
    "        factor_list = get_factors(x)\n",
    "        while len(factor_list) <= 2 and not is_square(x):\n",
    "            x += 1\n",
    "            factor_list = get_factors(x)\n",
    "        if is_square(x):\n",
    "            rows = int(np.sqrt(x))\n",
    "            columns = int(np.sqrt(x))\n",
    "\n",
    "        else:\n",
    "            rows = factor_list[int(len(factor_list)/2-1)]\n",
    "            columns = factor_list[int(len(factor_list)/2)]\n",
    "\n",
    "    return rows, columns\n",
    "\n",
    "\n",
    "def get_true_edges(gold_filename):\n",
    "    evaluator = Evaluator(gold_filename, '\\t')\n",
    "    edges = evaluator.gs_flat.tolist()\n",
    "    return edges, evaluator\n",
    "\n",
    "\n",
    "def get_edge_lags(data_filename):\n",
    "    df = pd.read_csv(data_filename, sep=\"\\t\")\n",
    "    gene_list = df.columns.values[1:].tolist()\n",
    "    experiment_list = get_experiment_list(data_filename, 21, 10)\n",
    "    xcorr_array = xcorr_experiments(experiment_list)\n",
    "    lags = calc_edge_lag(xcorr_array, gene_list, 0.1, 0.5, timestep=1)\n",
    "    return lags, df\n",
    "\n",
    "\n",
    "def get_network_changes(pickle_filename, edge_str='regulator-target', base_str='rank_importance_RF-td_21',\n",
    "                        shortener_str='rank_importance_', replace=''):\n",
    "    results_df = pd.read_pickle(pickle_filename)\n",
    "    edges = results_df[edge_str].values\n",
    "    baseline = results_df[base_str].values\n",
    "\n",
    "    rank_df = pd.DataFrame()\n",
    "    rank_df[edge_str] = edges\n",
    "    rank_df[('Base_%s' %replace)] = baseline\n",
    "    for column in results_df.columns:\n",
    "        if column != edge_str and column!=base_str:\n",
    "            short_name = column.replace(shortener_str, replace)\n",
    "            rank_df[short_name] = results_df[column].values\n",
    "    rank_df.set_index(['regulator-target'], inplace=True)\n",
    "    diff_df = (rank_df.T-rank_df.T.iloc[0]).T\n",
    "    parameters = set(rank_df.columns[1:].values)\n",
    "    return diff_df, rank_df, parameters\n",
    "\n",
    "\n",
    "def get_network_data(goldstandard, timeseries, ignore_self=True):\n",
    "    # Get true network\n",
    "    true_edges, evaluator = get_true_edges(goldstandard)\n",
    "    dg = nx.DiGraph()\n",
    "    dg.add_edges_from(true_edges)\n",
    "    \n",
    "    #Network statistics - deprecated\n",
    "    #degree = nx.degree_centrality(dg)\n",
    "    #b_cent = pd.DataFrame.from_dict({k: [v] for k, v in nx.edge_betweenness_centrality(dg).items()}, 'index')\n",
    "    #b_cent.columns = ['Bcent']\n",
    "    \n",
    "    #Calculate edge lags\n",
    "    edge_lags, data = get_edge_lags(timeseries)\n",
    "    if ignore_self:\n",
    "        edge_lags = edge_lags[edge_lags['Parent'] != edge_lags['Child']]\n",
    "    edge_df = pd.DataFrame(edge_lags['Lag'].values, index=edge_lags['Edge'].values, columns=['Lag'])\n",
    "\n",
    "    return true_edges, edge_df, data, dg, evaluator\n",
    "\n",
    "def get_signed_edges(signed):\n",
    "    df = pd.read_csv(signed, sep='\\t', header=None)\n",
    "    df['regulator-target'] = list(zip(df[0], df[1]))\n",
    "    df.set_index(['regulator-target'], inplace=True)\n",
    "    df.drop([0, 1], axis=1, inplace=True)\n",
    "    df.columns=['sign']\n",
    "    return df\n",
    "\n",
    "def calc_scores(ranking_df):\n",
    "    filtered_ranks = ranking_df.copy()\n",
    "    filtered_ranks.reset_index(level=0, inplace=True)\n",
    "    roc = []\n",
    "    aupr = []\n",
    "    for c in filtered_ranks.columns[1:]:\n",
    "        filtered_ranks.sort_values(filtered_ranks.columns[1], inplace=True)\n",
    "        roc.append(evaluator.calc_roc(filtered_ranks.iloc[:, :2])[2].values[-1])\n",
    "        aupr.append(evaluator.calc_pr(filtered_ranks.iloc[:, :2])[2].values[-1])\n",
    "        filtered_ranks.drop(c, axis=1, inplace=True)\n",
    "    return roc, aupr\n",
    "\n",
    "def calc_promotion(change_df, columns):\n",
    "    t_promoted = np.sum(change_df.loc[:, columns].values > 0, axis=0)\n",
    "    t_demoted = np.sum(change_df.loc[:, columns].values < 0, axis=0)\n",
    "    t_same = np.sum(change_df.loc[:, columns].values == 0, axis=0)\n",
    "\n",
    "    t_lagged = change_df[change_df['Lag'] > 0]\n",
    "    l_promoted = np.sum(t_lagged.loc[:, columns].values > 0, axis=0)\n",
    "    l_demoted = np.sum(t_lagged.loc[:, columns].values < 0, axis=0)\n",
    "    l_same = np.sum(t_lagged.loc[:, columns].values == 0, axis=0)\n",
    "    rows = ['true+', 'true-', 'true=', 'lag+', 'lag-', 'lag=']\n",
    "    return pd.DataFrame([t_promoted, t_demoted, t_same, l_promoted, l_demoted, l_same], index=rows, columns=columns).T\n",
    "\n",
    "def get_net_stats(dg):\n",
    "    g = dg.to_undirected()\n",
    "    assort = nx.degree_pearson_correlation_coefficient(dg)\n",
    "    if np.isnan(assort):\n",
    "        assort = 0\n",
    "    clust = nx.average_clustering(g)\n",
    "    trans= nx.transitivity(g)\n",
    "    try:\n",
    "        rad = nx.radius(g)\n",
    "    except nx.NetworkXError:\n",
    "        rad = 0\n",
    "    try:\n",
    "        diam = nx.diameter(g)\n",
    "    except nx.NetworkXError:\n",
    "        diam = 0\n",
    "    return [assort, clust, trans, rad, diam]\n",
    "\n",
    "def get_c_table(summary_df):\n",
    "    \"\"\"\n",
    "    C table format: [[lagged_promoted, lagged_not_promoted],\n",
    "                 [not_lagged_promoted, not_lagged_not_promoted]]\n",
    "    \"\"\"\n",
    "\n",
    "    c_table = np.array([[summary_df['lag+'], summary_df['lag-']+summary_df['lag=']],\n",
    "                        [summary_df['true+']-summary_df['lag+'],\n",
    "                         summary_df['true-']+summary_df['true=']-summary_df['lag-']-summary_df['lag=']]])\n",
    "    c_table = np.array([c_table[:, :, ii] for ii in range(c_table.shape[2])])\n",
    "    return c_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lag_range = {'ml_0': [0, 1], 'ml_1': [0, 2], 'ml_2': [0, 3], 'ml_3': [1, 2], 'ml_4': [1, 4], 'ml_5': [2, 3]}\n",
    "num_nets = 20\n",
    "methods = ['Dionesus', 'RF']\n",
    "replace_dict = {'Dionesus':'D', 'RF':'RF'}\n",
    "models = ['Ecoli', 'Yeast']\n",
    "result_types = ['te_change', 'te_rank', 'roc', 'pr']\n",
    "overall = {method:{model:{result:pd.DataFrame() for result in result_types} for model in models} \n",
    "                for method in methods}\n",
    "network_stats = {method:{model:{net:{} for net in range(1, num_nets+1)} for model in models} for method in methods}\n",
    "for ii, method in enumerate(methods):\n",
    "    for model in models:\n",
    "        for net in range(1, num_nets+1):\n",
    "            short = 'rank_importance_%s' %method\n",
    "            pickle_file = \"%s_net%i_%s_promotion.pkl\" % (model, net, method.lower())\n",
    "            base_str = ('rank_importance_%s-td_21' %method)\n",
    "            \n",
    "            roc_df = pd.DataFrame()\n",
    "            pr_df = pd.DataFrame()\n",
    "            # Get the network information\n",
    "            gold_file = \"../data/gnw_insilico/network_data/%s/%s-%i_goldstandard.tsv\" % (model, model, net)\n",
    "            signed_file = gold_file.replace('.tsv', '_signed.tsv')\n",
    "            data_file = \"../data/gnw_insilico/network_data/%s/%s-%i_timeseries.tsv\" % (model, model, net)\n",
    "            true_edges, edge_df, data, dg, evaluator = get_network_data(gold_file, data_file)\n",
    "            signed_edges = get_signed_edges(signed_file)\n",
    "        \n",
    "            change, ranks, params = get_network_changes(pickle_file, base_str= base_str, \n",
    "                                                        shortener_str=short, replace=replace_dict[method])\n",
    "            \n",
    "            change_df = change.reindex_axis(sorted(change.columns), axis=1)\n",
    "            ranks_df = ranks.reindex_axis(sorted(ranks.columns), axis=1)\n",
    "            conditions = change_df.columns.values\n",
    "            network_stats[method][model][net]['rank'] = ranks_df\n",
    "            network_stats[method][model][net]['rank_change'] = change_df\n",
    "        \n",
    "            # Calculate the auroc and aupr for each parameter set of the network\n",
    "            roc_df[model + str(net)], pr_df[model + str(net)]= calc_scores(ranks_df)\n",
    "            roc_df.index = conditions\n",
    "            pr_df.index = conditions\n",
    "            network_stats[method][model][net]['auroc'] = roc_df.T\n",
    "            network_stats[method][model][net]['aupr'] = pr_df.T\n",
    "            \n",
    "            # Compile results\n",
    "            full_change = pd.concat([edge_df, change_df], axis=1, join='inner')\n",
    "            full_rank = pd.concat([edge_df, ranks_df], axis=1, join='inner')\n",
    "            te_rank = pd.concat([signed_edges, full_rank[full_rank.index.isin(true_edges)]], \n",
    "                                        axis=1, join='inner')\n",
    "            te_change = pd.concat([signed_edges, full_change[full_change.index.isin(true_edges)]],\n",
    "                                           axis=1, join='inner')\n",
    "            promotions = calc_promotion(te_change, conditions)\n",
    "            stats = get_net_stats(dg)\n",
    "            network_stats[method][model][net]['conditions'] = conditions\n",
    "            network_stats[method][model][net]['change'] = full_change\n",
    "            network_stats[method][model][net]['rank'] = full_rank\n",
    "            network_stats[method][model][net]['te_change'] = te_change\n",
    "            network_stats[method][model][net]['te_rank'] = te_rank\n",
    "            network_stats[method][model][net]['promotions'] = promotions\n",
    "            network_stats[method][model][net]['contingency'] = get_c_table(promotions)\n",
    "            network_stats[method][model][net]['stats'] = pd.DataFrame(stats, index=['assort', 'clust', \n",
    "                                                                                    'trans', 'rad', 'diam'])\n",
    "\n",
    "\n",
    "# stats_df = pd.DataFrame(stats, index = roc_df.columns.values, columns = ['assort', 'clust', 'trans', 'rad', 'diam'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize Results at each level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(nan, 1.0)\n",
      "(0.70588235294117652, 0.21291987101812371)\n",
      "(0.48518918918918919, 0.010862258220910654)\n",
      "(0.37209302325581395, 0.00059678604791438272)\n",
      "(0.4626736111111111, 0.006611078391902515)\n",
      "(0.44788975021533162, 0.0059820461212942407)\n",
      "(0.35999999999999999, 0.00033992183432555187)\n",
      "(0.37309489941068891, 0.00073622441705142405)\n",
      "(0.39983494945327008, 0.0014315216493716852)\n",
      "(0.9464285714285714, 0.89297761029133271)\n"
     ]
    }
   ],
   "source": [
    "s_dict = {}\n",
    "for meth, mod in network_stats.items():\n",
    "    s_dict[meth] = {\"aupr\": pd.DataFrame(), \"auroc\":pd.DataFrame(), \n",
    "                          \"te_change\":pd.DataFrame(), \"te_rank\":pd.DataFrame()}\n",
    "    for m in mod.keys():\n",
    "        s_dict[meth][m] = {\"aupr\": pd.DataFrame(), \"auroc\":pd.DataFrame(), \n",
    "                                 \"te_change\":pd.DataFrame(), \"te_rank\":pd.DataFrame()}\n",
    "        # Caclulate it for each model organism\n",
    "        for k in network_stats[meth][m].keys():\n",
    "            s_dict[meth][m]['aupr'] = pd.concat([s_dict[meth][m]['aupr'], \n",
    "                                                 network_stats[meth][m][k]['aupr']], join='inner')\n",
    "            s_dict[meth][m]['auroc'] = pd.concat([s_dict[meth][m]['auroc'], \n",
    "                                                  network_stats[meth][m][k]['auroc']], join='inner')\n",
    "            s_dict[meth][m]['te_change'] = pd.concat([s_dict[meth][m]['te_change'], \n",
    "                                                      network_stats[meth][m][k]['te_change']], join='outer')\n",
    "            s_dict[meth][m]['te_rank'] = pd.concat([s_dict[meth][m]['te_rank'], \n",
    "                                                    network_stats[meth][m][k]['te_rank']], join='outer')\n",
    "        s_dict[meth][m]['promotion'] = calc_promotion(s_dict[meth][m]['te_change'], s_dict[meth][m]['aupr'].columns)\n",
    "        s_dict[meth][m]['contingency'] = get_c_table(s_dict[meth][m]['promotion'])\n",
    "        \n",
    "        #Summarize it for each method\n",
    "        s_dict[meth]['aupr'] = pd.concat([s_dict[meth]['aupr'], s_dict[meth][m]['aupr']], join='inner')\n",
    "        s_dict[meth]['auroc'] = pd.concat([s_dict[meth]['auroc'], s_dict[meth][m]['auroc']], join='inner')\n",
    "        s_dict[meth]['te_change'] = pd.concat([s_dict[meth]['te_change'], s_dict[meth][m]['te_change']], join='outer')\n",
    "        s_dict[meth]['te_rank'] = pd.concat([s_dict[meth]['te_rank'], s_dict[meth][m]['te_rank']], join='outer')\n",
    "    s_dict[meth]['promotion'] = calc_promotion(s_dict[meth]['te_change'], s_dict[meth]['aupr'].columns)\n",
    "    s_dict[meth]['contingency'] = get_c_table(s_dict[meth]['promotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate true edges promoted\n",
    "conditions = te_change.columns.values[4:]\n",
    "summary_df = calc_promotion(te_change, conditions)\n",
    "\n",
    "for ii in range(c_table.shape[-1]):\n",
    "    print(conditions[ii], fisher_exact(c_table[:, :, ii])[1])\n",
    "\n",
    "# for ii, run in enumerate(conditions):\n",
    "#     if 'ml' in run:\n",
    "#         key = run.split('-')[1]\n",
    "#         min_lag = lag_range[key][0]\n",
    "#         max_lag = lag_range[key][1]\n",
    "#         in_range = true_edge_change[(true_edge_change['Lag'] >= min_lag) & (true_edge_change['Lag'] <= max_lag)][[run]]\n",
    "#         print(run, np.sum(in_range.values > 0)/len(in_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = ['b', 'r', 'g']\n",
    "plt.figure()\n",
    "for ii in range(3,6):\n",
    "    if ii==3:\n",
    "        plt.bar(range(len(summary_df)), summary_df.iloc[:, ii]/345, color=c[ii-3])\n",
    "    else:\n",
    "        bar_bottom = np.sum(summary_df.iloc[:, 3:ii]/345, axis=1)\n",
    "        plt.bar(range(len(summary_df)), summary_df.iloc[:, ii]/345, color=c[ii-3], bottom=bar_bottom)\n",
    "# summary_df.columns[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(2, 2, figsize=(20,10))\n",
    "# axarr[0, 0].plot([0.3, 0.9], [0.3, 0.9], '-', c='0.5', lw=5)\n",
    "# axarr[1, 1].plot([0.3, 0.9], [0.3, 0.9], '-', c='0.5', lw=5)\n",
    "for ii in range(2,len(roc_df)):\n",
    "    m = roc_df.index[ii]\n",
    "    if 'D' in m:\n",
    "        roc_pval = ttest_rel(roc_df.iloc[0], roc_df.iloc[ii])[1]\n",
    "        pr_pval = ttest_rel(pr_df.iloc[0], pr_df.iloc[ii])[1]\n",
    "        if roc_pval <0.05:\n",
    "            axarr[0, 0].plot(roc_df.iloc[0], roc_df.iloc[ii], '.', label=m, ms=10)\n",
    "        if pr_pval <0.05:\n",
    "            axarr[0, 1].plot(pr_df.iloc[0], pr_df.iloc[ii], '.', label=m, ms=10)\n",
    "        \n",
    "    else:\n",
    "        roc_pval = ttest_rel(roc_df.iloc[1], roc_df.iloc[ii])[1]\n",
    "        pr_pval = ttest_rel(pr_df.iloc[0], pr_df.iloc[ii])[1]\n",
    "        if roc_pval < 0.05:\n",
    "            axarr[1, 0].plot(roc_df.iloc[1], roc_df.iloc[ii], '.', label=m, ms=10)\n",
    "        if pr_pval <0.05:\n",
    "            axarr[1, 1].plot(pr_df.iloc[0], pr_df.iloc[ii], '.', label=m, ms=10)\n",
    "\n",
    "\n",
    "# axarr[0].set_xlabel('Baseline')\n",
    "# axarr[0].set_ylabel('SWING score')\n",
    "# axarr[0].legend(loc='best')\n",
    "# axarr[1].set_xlabel('Baseline')\n",
    "# axarr[1].set_ylabel('SWING score')\n",
    "# axarr[1].legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for row in range(len(roc_df)):\n",
    "    for col in stats_df.columns.values:\n",
    "        plt.figure()\n",
    "        print(roc_df.index.values[row], col, linregress(stats_df[col], roc_df.iloc[row]).rvalue)\n",
    "#         plt.plot(stats_df[col], roc_df.iloc[1], '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
